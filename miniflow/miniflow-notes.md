If you see the loss rate bouncing back and forth, it means the learning rate is too large to settle into the local minimum.  
Think about this graphically in terms of the curve and the ball bouncing down steps of the curve.  
It'd basically be if the ball was too bouncy.

Epoch: 97, Loss: 7.109
Epoch: 98, Loss: 6.813
Epoch: 99, Loss: 7.521
Epoch: 100, Loss: 6.590
